import os
import re
from typing import Any, Generator

import charset_normalizer
import gradio as gr
import pyperclip
import requests
from llama_cpp import Llama

model = None
stop_gen = False

theme = gr.themes.Base(
    primary_hue="violet",
    secondary_hue="indigo",
    radius_size="sm",
).set(
    background_fill_primary='*neutral_50',
    border_color_accent='*neutral_50',
    color_accent_soft='*neutral_50',
    shadow_drop='none',
    shadow_drop_lg='none',
    shadow_inset='none',
    shadow_spread='none',
    shadow_spread_dark='none',
    layout_gap='*spacing_xl',
    checkbox_background_color='*primary_50',
    checkbox_background_color_focus='*primary_200'
)


def get_html(url: str) -> str:
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        # å‘é€å¸¦è¯·æ±‚å¤´çš„GETè¯·æ±‚
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        html = response.text
        return html
    except requests.exceptions.HTTPError as e:
        return f"HTTPé”™è¯¯: çŠ¶æ€ç  {e.response.status_code}"
    except requests.exceptions.RequestException as e:
        return f"è¯·æ±‚å¤±è´¥: {e}"
    except Exception as e:
        return f"å…¶ä»–é”™è¯¯: {e}"


def stop_generate():
    global stop_gen
    stop_gen = True


def load_html_file(file_path: str) -> str:
    with open(file_path, 'rb') as file:
        content_bytes = file.read()
        encoding = charset_normalizer.detect(content_bytes)
    with open(file_path, 'r', encoding=encoding['encoding']) as f:
        return f.read()


def unload_model() -> str:
    global model
    model = None
    return "æ¨¡å‹å·²å¸è½½"


def load_model(model_path: str,
               n_gpu_layers: int,
               n_ctx: int) -> (str, gr.components.dropdown.Dropdown):
    global model
    model = None
    model = Llama(model_path=model_path, n_gpu_layers=n_gpu_layers, n_ctx=n_ctx)
    metadata = model.metadata
    if "general.version" in metadata.keys():
        version = metadata["general.version"]
        if version == "v2":
            return f"æ¨¡å‹ '{model_path}' å·²æˆåŠŸåŠ è½½", gr.Dropdown(
                label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="2", interactive=True)
        else:
            return f"æ¨¡å‹ '{model_path}' å·²æˆåŠŸåŠ è½½ï¼Œä½†å®ƒçœ‹èµ·æ¥ä¸åƒä¸€ä»£æ¨¡å‹ï¼Œä¹Ÿä¸åƒäºŒä»£æ¨¡å‹", gr.Dropdown(
                label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="1", interactive=True)
    else:
        return f"æ¨¡å‹ '{model_path}' å·²æˆåŠŸåŠ è½½", gr.Dropdown(
            label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="1", interactive=True)


def clean_html(html: str, repl_svg: bool = False,
               repl_base64: bool = False,
               new_svg: str = "this is a placeholder",
               new_img: str = "#") -> str:
    # åŒ¹é…æ¨¡å¼
    script = r"<[ ]*script.*?\/[ ]*script[ ]*>"
    style = r"<[ ]*style.*?\/[ ]*style[ ]*>"
    meta = r"<[ ]*meta.*?>"
    comment = r"<[ ]*!--.*?--[ ]*>"
    link = r"<[ ]*link.*?>"
    svg = r"(<svg[^>]*>)(.*?)(<\/svg>)"
    base64_img = r'<img[^>]+src="data:image/[^;]+;base64,[^"]+"[^>]*>'

    def replace_svg(html: str, new_content: str) -> str:
        return re.sub(
            svg,
            lambda match: f"{match.group(1)}{new_content}{match.group(3)}",
            html,
            flags=re.DOTALL,
        )

    def replace_base64_images(html: str, new_image_src) -> str:
        return re.sub(base64_img, f'<img src="{new_image_src}"/>', html)

    html = re.sub(
        script, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        style, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        meta, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        comment, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        link, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )

    if repl_svg:
        html = replace_svg(html, new_svg)
    if repl_base64:
        html = replace_base64_images(html, new_img)

    return html


def cal_token_count(html: str, max_tokens: int) -> str:
    global model
    if model is None:
        return "æœªåŠ è½½æ¨¡å‹ï¼Œæ— æ³•è®¡ç®— Token æ•°é‡"
    else:
        if html is not None:
            tokens = model.tokenize(html.encode('utf-8'))
            tokens_cleaned = model.tokenize(clean_html(html).encode('utf-8'))
            tokens_count = len(tokens)
            tokens_count_cleaned = len(tokens_cleaned)
            if tokens_count_cleaned > max_tokens:
                return \
                    f"""âš ï¸HTML è¿‡é•¿ï¼Œå°è¯•å‡å°‘æ–‡ä»¶é•¿åº¦æˆ–å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦âš ï¸  
    Token æ•°é‡ï¼š{tokens_count}  
    é¢„æ¸…ç† HTML åçš„é¢„è®¡ Token æ•°é‡ï¼š{tokens_count_cleaned}"""
            elif tokens_count > max_tokens >= tokens_count_cleaned:
                return \
                    f"""âš ï¸HTML è¿‡é•¿ï¼Œéœ€è¦é¢„æ¸…ç†âš ï¸  
    Token æ•°é‡ï¼š{tokens_count}  
    é¢„æ¸…ç† HTML åçš„é¢„è®¡ Token æ•°é‡ï¼š{tokens_count_cleaned}"""
            else:
                return \
                    f"""
    Token æ•°é‡ï¼š{tokens_count}  
    é¢„æ¸…ç† HTML åçš„é¢„è®¡ Token æ•°é‡ï¼š{tokens_count_cleaned}
    """
        else:
            return "æ–‡æœ¬ä¸ºç©º"


def generate_response(html_content: str, max_tokens: int,
                      temperature: float, top_p: float,
                      model_gen: str, instruction: str,
                      schema: str, html_clean: bool,
                      repl_svg: bool, repl_base64: bool,
                      new_svg: str, new_img: str) -> Generator[str | Any, Any, str | Any]:
    """
    æœ€é‡è¦çš„éƒ¨åˆ†ï¼Œç”Ÿæˆ Markdown

    :param html_content: å°†è¦è½¬æ¢çš„ HTML å†…å®¹
    :param max_tokens: æœ€å¤§ token æ•°é‡
    :param temperature: æ¸©åº¦
    :param top_p: top_p
    :param model_gen: æ¨¡å‹ä»£æ•°
    :param instruction: è‡ªå®šä¹‰æç¤ºè¯ï¼Œä»…é€‚ç”¨äºç¬¬äºŒä»£æ¨¡å‹
    :param schema: è‡ªå®šä¹‰è¾“å‡º JSON æ ¼å¼
    :param html_clean: æ˜¯å¦é¢„æ¸…ç† HTML å†…å®¹
    :param repl_svg: æ˜¯å¦æ›¿æ¢ SVG
    :param repl_base64: æ˜¯å¦æ›¿æ¢ base64 å½¢å¼çš„å›¾ç‰‡
    :param new_svg: æ–°çš„ SVG
    :param new_img: æ–°çš„å›¾ç‰‡

    :return: output: Markdown
    """
    global model, stop_gen
    stop_gen = False

    if html_clean:
        html_content = clean_html(html=html_content, repl_svg=repl_svg, repl_base64=repl_base64, new_svg=new_svg,
                                  new_img=new_img)

    if model is None:
        return "æ¨¡å‹æœªåŠ è½½"

    # æ„å»ºæç¤ºè¯
    if model_gen == "2":
        if not instruction:
            instruction = "Extract the main content from the given HTML and convert it to Markdown format."
        if schema:
            instruction = "Extract the specified information from a list of news threads and present it in a structured JSON format."
            prompt = f"{instruction}\n```html\n{html_content}\n```\nThe JSON schema is as follows:```json\n{schema}\n```"
        else:
            prompt = f"{instruction}\n```html\n{html_content}\n```"
        input_text = prompt
    else:
        input_text = f"{html_content}"
    message = [
        {
            "role": "user",
            "content": input_text
        }
    ]
    # æµå¼ç”Ÿæˆ
    temp = model.create_chat_completion(messages=message, max_tokens=max_tokens,
                                        temperature=temperature, top_p=top_p, stream=True)
    output = ""
    for chunk in temp:
        if not "content" in chunk["choices"][0]["delta"]:
            continue
        output += chunk["choices"][0]["delta"]["content"]
        if stop_gen:  # æ£€æµ‹stop_genæ˜¯å¦ä¸ºçœŸ
            break
        yield output
    return output


def md_deliver(text: str) -> str:
    lines = text.split("\n")
    if lines[0] == "```markdown" and lines[-2] == "```" and len(lines) >= 2:
        return "\n".join(lines[1:-2])
    else:
        return text


def html_deliver(text: str) -> str:
    return text


def update_html_prev(html_file: str, html_url: str) -> (gr.components.markdown.Markdown, str):
    html_content = ""
    if html_file and not html_url:
        html_path = os.path.join('html', html_file)
        html_content = load_html_file(html_path)
    elif html_url:
        gr.Info("æ­£åœ¨å°è¯•è¯»å– HTMLï¼Œå…·ä½“æ—¶é—´ä¾ç½‘ç»œçŠ¶å†µè€Œå®š")
        html_content = get_html(html_url)
    return gr.Markdown(html_content), html_content


def scan_models() -> list:
    return [f for f in os.listdir("models") if f.lower().endswith(".gguf")]


def refresh_model_list(current_selection: str) -> gr.components.dropdown.Dropdown:
    file_list = scan_models()
    if current_selection in file_list:
        new_selection = current_selection
    elif file_list:
        new_selection = file_list[0]
    else:
        new_selection = None

    return gr.Dropdown(label="é€‰æ‹©æ¨¡å‹", choices=file_list, interactive=True, value=new_selection)


def copy(content: str, remove_code_block: bool):
    if remove_code_block:
        content = md_deliver(content)
    pyperclip.copy(content)


def toggle_repl_svg(repl: bool) -> gr.components.textbox.Textbox:
    return gr.Textbox(interactive=True,
                      label="æ›¿æ¢åçš„ SVG",
                      visible=True) if repl else gr.Textbox(interactive=True,
                                                            label="æ›¿æ¢åçš„ SVG",
                                                            visible=False)


def toggle_repl_img(repl: bool) -> gr.components.textbox.Textbox:
    return gr.Textbox(interactive=True,
                      label="æ›¿æ¢åçš„å›¾ç‰‡",
                      visible=True) if repl else gr.Textbox(interactive=True,
                                                            label="æ›¿æ¢åçš„å›¾ç‰‡",
                                                            visible=False)


with gr.Blocks(theme=theme) as demo:
    gr.Markdown("## ReaderLM WebUI")
    html_content_store = gr.State()

    with gr.Tab("ç”Ÿæˆ"):
        with gr.Row():
            with gr.Column():
                token_count = gr.Markdown()
                html_url = gr.Textbox(label="è¾“å…¥ URL")
                commit_url = gr.Button("æäº¤ URL")
                html_file = gr.File(label="æˆ–é€‰æ‹© HTML æ–‡ä»¶", file_count="single", file_types=[".html"],
                                    type="filepath")
                html_preview = gr.Markdown()
            with gr.Column():
                with gr.Row():
                    generate_button = gr.Button("è½¬æ¢ä¸º Markdown", variant="primary")
                    stop_button = gr.Button("åœæ­¢ç”Ÿæˆ")
                    copy_button = gr.Button("å¤åˆ¶")
                output_text = gr.Textbox(label="Markdown", interactive=False, lines=20)
    with gr.Tab("Markdown"):
        render_button = gr.Button("æ¸²æŸ“ Markdown")
        output_md = gr.Markdown("")
    with gr.Tab("HTML"):
        html_render_warning = gr.Markdown("HTML ä¸­çš„ CSS å¯èƒ½ä¼šå¯¹ UI äº§ç”Ÿæ„æ–™ä¹‹å¤–çš„å½±å“ï¼Œè¯·è°¨æ…åŠ è½½")
        html_render_button = gr.Button("æ¸²æŸ“ HTML")
        output_html = gr.HTML("")
    with gr.Tab("è®¾ç½®"):
        gr.Markdown("æ¨¡å‹è®¾ç½®")
        with gr.Row():
            n_gpu_layers_input = gr.Number(label="GPU å±‚æ•°", value=-1, maximum=128, minimum=-1)
            model_files = scan_models()
            model_file_dropdown = gr.Dropdown(label="é€‰æ‹©æ¨¡å‹", choices=model_files)
            model_type = gr.Dropdown(label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="1", interactive=True)
        with gr.Row():
            load_model_button = gr.Button("åŠ è½½æ¨¡å‹", variant="primary", scale=10)
            refresh_models_list_btn = gr.Button("ğŸ”„", min_width=10, scale=1)
            unload_model_button = gr.Button("å¸è½½æ¨¡å‹", scale=10)
        model_load_info = gr.Markdown("")
        gr.Markdown("ç”Ÿæˆè®¾ç½®")
        with gr.Row():
            n_ctx_input = gr.Number(label="ä¸Šä¸‹æ–‡é•¿åº¦", value=204800, minimum=1)
            max_tokens_input = gr.Number(label="æœ€å¤§æ–°åˆ†é… token æ•°é‡", value=102400, minimum=1)
        with gr.Row():
            temperature_input = gr.Number(label="Temperature", value=0.8, minimum=0)
            top_p_input = gr.Number(label="Top P", value=0.95, minimum=0, maximum=1)
        remove_code_block = gr.Checkbox(interactive=True, value=True,
                                        label="ç§»é™¤æœ€å¤–å±‚çš„ä»£ç å—ï¼ˆé€šå¸¸å‡ºç°äº V2 æ¨¡å‹ï¼‰")
        gr.Markdown("HTML è®¾ç½®")
        with gr.Row():
            clean_html_cbox = gr.Checkbox(interactive=True, value=True, label="æ¸…ç† HTML")
            repl_svg = gr.Checkbox(interactive=True, value=False, label="æ›¿æ¢ SVG")
            repl_img = gr.Checkbox(interactive=True, value=False, label="æ›¿æ¢ Base64 å½¢å¼çš„å›¾ç‰‡")
        with gr.Row():
            new_svg = gr.Textbox(interactive=True, label="æ›¿æ¢åçš„ SVG", visible=False)
            new_img = gr.Textbox(interactive=True, label="æ›¿æ¢åçš„å›¾ç‰‡", visible=False)
        gr.Markdown("æŒ‡ä»¤è®¾ç½® - åªå¯¹ç¬¬äºŒä»£æ¨¡å‹ç”Ÿæ•ˆï¼Œä¸¤ä¸ªè®¾ç½®äº’æ–¥ï¼ŒåŒæ—¶åªæœ‰ä¸€ä¸ªç”Ÿæ•ˆ")
        with gr.Row():
            custom_instruction = gr.Textbox(interactive=True, label="è‡ªå®šä¹‰æç¤ºè¯")
            json_schema = gr.Textbox(interactive=True, label="è‡ªå®šä¹‰è¾“å‡º JSON æ ¼å¼")

    repl_svg.change(
        fn=toggle_repl_svg,
        inputs=repl_svg,
        outputs=new_svg
    )

    repl_img.change(
        fn=toggle_repl_img,
        inputs=repl_img,
        outputs=new_img
    )

    html_file.change(
        update_html_prev,
        inputs=[html_file, html_url],
        outputs=[html_preview, html_content_store]
    )

    commit_url.click(
        update_html_prev,
        inputs=[html_file, html_url],
        outputs=[html_preview, html_content_store]
    )

    html_content_store.change(
        fn=cal_token_count,
        inputs=[html_content_store, max_tokens_input],
        outputs=token_count
    )

    load_model_button.click(
        fn=lambda model_file, n_gpu_layers, n_ctx: load_model(
            os.path.join('models', model_file), n_gpu_layers, n_ctx
        ),
        inputs=[model_file_dropdown, n_gpu_layers_input, n_ctx_input],
        outputs=[model_load_info, model_type]
    )

    generate_button.click(
        fn=generate_response,
        inputs=[html_preview, max_tokens_input, temperature_input, top_p_input, model_type, custom_instruction,
                json_schema, clean_html_cbox, repl_svg, repl_img, new_svg, new_img],
        outputs=output_text
    )

    render_button.click(
        fn=md_deliver,
        inputs=output_text,
        outputs=output_md
    )

    stop_button.click(
        fn=stop_generate,
        inputs=None,
        outputs=None
    )

    html_render_button.click(
        fn=html_deliver,
        inputs=html_preview,
        outputs=output_html
    )

    unload_model_button.click(
        fn=unload_model,
        inputs=None,
        outputs=model_load_info
    )

    copy_button.click(
        fn=copy,
        inputs=[output_text, remove_code_block],
        outputs=None
    )

    refresh_models_list_btn.click(
        fn=refresh_model_list,
        inputs=model_file_dropdown,
        outputs=model_file_dropdown
    )

demo.launch()
