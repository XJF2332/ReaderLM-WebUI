import os
import re
from typing import Any, Generator

import charset_normalizer
import gradio as gr
import pyperclip
from llama_cpp import Llama

model = None
stop_gen = False

theme = gr.themes.Base(
    primary_hue="violet",
    secondary_hue="indigo",
    radius_size="sm",
).set(
    background_fill_primary='*neutral_50',
    border_color_accent='*neutral_50',
    color_accent_soft='*neutral_50',
    shadow_drop='none',
    shadow_drop_lg='none',
    shadow_inset='none',
    shadow_spread='none',
    shadow_spread_dark='none',
    layout_gap='*spacing_xl',
    checkbox_background_color='*primary_50',
    checkbox_background_color_focus='*primary_200'
)


def stop_generate():
    global stop_gen
    stop_gen = True


def load_html_file(file_path):
    with open(file_path, 'rb') as file:
        content_bytes = file.read()
        encoding = charset_normalizer.detect(content_bytes)
    with open(file_path, 'r', encoding=encoding['encoding']) as f:
        return f.read()


def unload_model():
    global model
    model = None
    return "æ¨¡å‹å·²å¸è½½"


def load_model(model_path:str, n_gpu_layers, n_ctx):
    global model
    model = None
    model = Llama(model_path=model_path, n_gpu_layers=n_gpu_layers, n_ctx=n_ctx)
    metadata = model.metadata
    if "general.version" in metadata.keys():
        version = metadata["general.version"]
        if version == "v2":
            return f"æ¨¡å‹ '{model_path}' å·²æˆåŠŸåŠ è½½", gr.Dropdown(
                label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="2", interactive=True)
        else:
            return f"æ¨¡å‹ '{model_path}' å·²æˆåŠŸåŠ è½½ï¼Œä½†å®ƒçœ‹èµ·æ¥ä¸åƒä¸€ä»£æ¨¡å‹ï¼Œä¹Ÿä¸åƒäºŒä»£æ¨¡å‹", gr.Dropdown(
                label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="1", interactive=True)
    else:
        return f"æ¨¡å‹ '{model_path}' å·²æˆåŠŸåŠ è½½", gr.Dropdown(
            label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="1", interactive=True)


def clean_html(html: str, repl_svg: bool = False,
               repl_base64: bool = False,
               new_svg: str = "this is a placeholder",
               new_img: str = "#") -> str:
    # åŒ¹é…æ¨¡å¼
    script = r"<[ ]*script.*?\/[ ]*script[ ]*>"
    style = r"<[ ]*style.*?\/[ ]*style[ ]*>"
    meta = r"<[ ]*meta.*?>"
    comment = r"<[ ]*!--.*?--[ ]*>"
    link = r"<[ ]*link.*?>"
    svg = r"(<svg[^>]*>)(.*?)(<\/svg>)"
    base64_img = r'<img[^>]+src="data:image/[^;]+;base64,[^"]+"[^>]*>'

    def replace_svg(html: str, new_content: str) -> str:
        return re.sub(
            svg,
            lambda match: f"{match.group(1)}{new_content}{match.group(3)}",
            html,
            flags=re.DOTALL,
        )

    def replace_base64_images(html: str, new_image_src) -> str:
        return re.sub(base64_img, f'<img src="{new_image_src}"/>', html)

    html = re.sub(
        script, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        style, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        meta, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        comment, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )
    html = re.sub(
        link, "", html, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
    )

    if repl_svg:
        html = replace_svg(html, new_svg)
    if repl_base64:
        html = replace_base64_images(html, new_img)

    return html

def cal_token_count(html_path: str, max_tokens: int) -> str:
    if html_path is not None:
        html = load_html_file(html_path)
        tokens = model.tokenize(html.encode('utf-8'))
        tokens_cleaned = model.tokenize(clean_html(html).encode('utf-8'))
        tokens_count = len(tokens)
        tokens_count_cleaned = len(tokens_cleaned)
        if tokens_count_cleaned > max_tokens:
            return \
f"""âš ï¸HTML è¿‡é•¿ï¼Œå°è¯•å‡å°‘æ–‡ä»¶é•¿åº¦æˆ–å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦âš ï¸  
Token æ•°é‡ï¼š{tokens_count}  
é¢„æ¸…ç† HTML åçš„é¢„è®¡ Token æ•°é‡ï¼š{tokens_count_cleaned}"""
        elif tokens_count > max_tokens >= tokens_count_cleaned:
            return \
f"""âš ï¸HTML è¿‡é•¿ï¼Œéœ€è¦é¢„æ¸…ç†âš ï¸  
Token æ•°é‡ï¼š{tokens_count}  
é¢„æ¸…ç† HTML åçš„é¢„è®¡ Token æ•°é‡ï¼š{tokens_count_cleaned}"""
        else:
            return \
f"""
Token æ•°é‡ï¼š{tokens_count}  
é¢„æ¸…ç† HTML åçš„é¢„è®¡ Token æ•°é‡ï¼š{tokens_count_cleaned}
"""
    else:
        return "æ–‡æœ¬ä¸ºç©º"


def generate_response(html_path: str, max_tokens: int,
                      temperature: float, top_p: float,
                      model_gen: str, instruction: str,
                      schema: str, html_clean: bool,
                      repl_svg: bool, repl_base64: bool,
                      new_svg: str, new_img: str) -> Generator[str | Any, Any, str | Any]:
    """
    æœ€é‡è¦çš„éƒ¨åˆ†ï¼Œç”Ÿæˆ Markdown

    :param html_path: å°†è¦è½¬æ¢çš„ HTML è·¯å¾„
    :param max_tokens: æœ€å¤§ token æ•°é‡
    :param temperature: æ¸©åº¦
    :param top_p: top_p
    :param model_gen: æ¨¡å‹ä»£æ•°
    :param instruction: è‡ªå®šä¹‰æç¤ºè¯ï¼Œä»…é€‚ç”¨äºç¬¬äºŒä»£æ¨¡å‹
    :param schema: è‡ªå®šä¹‰è¾“å‡º JSON æ ¼å¼
    :param html_clean: æ˜¯å¦é¢„æ¸…ç† HTML å†…å®¹
    :param repl_svg: æ˜¯å¦æ›¿æ¢ SVG
    :param repl_base64: æ˜¯å¦æ›¿æ¢ base64 å½¢å¼çš„å›¾ç‰‡
    :param new_svg: æ–°çš„ SVG
    :param new_img: æ–°çš„å›¾ç‰‡

    :return: output: Markdown
    """
    global model, stop_gen
    stop_gen = False
    html_path = os.path.join('html', html_path)
    html_loaded = load_html_file(html_path)

    if html_clean:
        html_loaded = clean_html(html=html_loaded, repl_svg=repl_svg, repl_base64=repl_base64, new_svg=new_svg,
                                 new_img=new_img)

    if model is None:
        return "æ¨¡å‹æœªåŠ è½½"

    # æ„å»ºæç¤ºè¯
    if model_gen == "2":
        if not instruction:
            instruction = "Extract the main content from the given HTML and convert it to Markdown format."
        if schema:
            instruction = "Extract the specified information from a list of news threads and present it in a structured JSON format."
            prompt = f"{instruction}\n```html\n{html_loaded}\n```\nThe JSON schema is as follows:```json\n{schema}\n```"
        else:
            prompt = f"{instruction}\n```html\n{html_loaded}\n```"
        input_text = prompt
    else:
        input_text = f"{html_loaded}"
    message = [
        {
            "role": "user",
            "content": input_text
        }
    ]
    # æµå¼ç”Ÿæˆ
    temp = model.create_chat_completion(messages=message, max_tokens=max_tokens, temperature=temperature, top_p=top_p,
                                        stream=True)
    output = ""
    for chunk in temp:
        if not "content" in chunk["choices"][0]["delta"]:
            continue
        output += chunk["choices"][0]["delta"]["content"]
        if stop_gen:  # æ£€æµ‹stop_genæ˜¯å¦ä¸ºçœŸ
            break
        yield output
    return output


def md_deliver(text):
    lines = text.split("\n")
    if lines[0] == "```" and lines[-1] == "```" and len(lines) >= 2:
        return "\n".join(lines[1:-1])
    else:
        return text


def html_deliver(text):
    return text


def update_html_prev(html_file):
    try:
        html_path = os.path.join('html', html_file)
        html_loaded = load_html_file(html_path)
        html_prev = gr.Markdown(html_loaded)
        return html_prev
    except:
        html_prev = gr.Markdown("")
        return html_prev


def scan_models():
    return [f for f in os.listdir("models") if f.lower().endswith(".gguf")]


def refresh_model_list(current_selection):
    file_list = scan_models()
    if current_selection in file_list:
        new_selection = current_selection
    elif file_list:
        new_selection = file_list[0]
    else:
        new_selection = None

    return gr.Dropdown(label="é€‰æ‹©æ¨¡å‹", choices=file_list, interactive=True, value=new_selection)


def copy(content):
    pyperclip.copy(content)


def show_repl_svg(repl):
    return gr.Textbox(interactive=True,
                      label="æ›¿æ¢åçš„ SVG",
                      visible=True) if repl else gr.Textbox(interactive=True,
                                                            label="æ›¿æ¢åçš„ SVG",
                                                            visible=False)


def show_repl_img(repl):
    return gr.Textbox(interactive=True,
                      label="æ›¿æ¢åçš„å›¾ç‰‡",
                      visible=True) if repl else gr.Textbox(interactive=True,
                                                            label="æ›¿æ¢åçš„å›¾ç‰‡",
                                                            visible=False)


with gr.Blocks(theme=theme) as demo:
    gr.Markdown("## ReaderLM WebUI")

    with gr.Tab("ç”Ÿæˆ"):
        with gr.Row():
            with gr.Column():
                token_count = gr.Markdown()
                html_file = gr.File(label="é€‰æ‹© HTML æ–‡ä»¶", file_count="single", file_types=[".html"], type="filepath")
                html_preview = gr.Markdown()
            with gr.Column():
                with gr.Row():
                    generate_button = gr.Button("è½¬æ¢ä¸º Markdown", variant="primary")
                    stop_button = gr.Button("åœæ­¢ç”Ÿæˆ")
                    copy_button = gr.Button("å¤åˆ¶")
                output_text = gr.Textbox(label="Markdown", interactive=False, lines=20)
    with gr.Tab("Markdown"):
        render_button = gr.Button("æ¸²æŸ“ Markdown")
        output_md = gr.Markdown("")
    with gr.Tab("HTML"):
        html_render_button = gr.Button("æ¸²æŸ“ HTML")
        output_html = gr.HTML("")
    with gr.Tab("è®¾ç½®"):
        gr.Markdown("æ¨¡å‹è®¾ç½®")
        with gr.Row():
            n_gpu_layers_input = gr.Number(label="GPU å±‚æ•°", value=-1)
            model_files = scan_models()
            model_file_dropdown = gr.Dropdown(label="é€‰æ‹©æ¨¡å‹", choices=model_files)
            model_type = gr.Dropdown(label="æ¨¡å‹ä»£æ•°", choices=["1", "2"], value="1", interactive=True)
        with gr.Row():
            load_model_button = gr.Button("åŠ è½½æ¨¡å‹", variant="primary", scale=10)
            refresh_models_list_btn = gr.Button("ğŸ”„", min_width=10, scale=1)
            unload_model_button = gr.Button("å¸è½½æ¨¡å‹", scale=10)
        model_load_info = gr.Markdown("")
        gr.Markdown("ç”Ÿæˆè®¾ç½®")
        with gr.Row():
            n_ctx_input = gr.Number(label="ä¸Šä¸‹æ–‡é•¿åº¦", value=204800)
            max_tokens_input = gr.Number(label="æœ€å¤§æ–°åˆ†é… token æ•°é‡", value=102400)
        with gr.Row():
            temperature_input = gr.Number(label="Temperature", value=0.8)
            top_p_input = gr.Number(label="Top P", value=0.95)
        gr.Markdown("HTML è®¾ç½®")
        with gr.Row():
            clean_html_cbox = gr.Checkbox(interactive=True, value=True, label="æ¸…ç† HTML")
            repl_svg = gr.Checkbox(interactive=True, value=False, label="æ›¿æ¢ SVG")
            repl_img = gr.Checkbox(interactive=True, value=False, label="æ›¿æ¢ Base64 å½¢å¼çš„å›¾ç‰‡")
        with gr.Row():
            new_svg = gr.Textbox(interactive=True, label="æ›¿æ¢åçš„ SVG", visible=False)
            new_img = gr.Textbox(interactive=True, label="æ›¿æ¢åçš„å›¾ç‰‡", visible=False)
        gr.Markdown("æŒ‡ä»¤è®¾ç½® - åªå¯¹ç¬¬äºŒä»£æ¨¡å‹ç”Ÿæ•ˆï¼Œä¸¤ä¸ªè®¾ç½®äº’æ–¥ï¼ŒåŒæ—¶åªæœ‰ä¸€ä¸ªç”Ÿæ•ˆ")
        with gr.Row():
            custom_instruction = gr.Textbox(interactive=True, label="è‡ªå®šä¹‰æç¤ºè¯")
            json_schema = gr.Textbox(interactive=True, label="è‡ªå®šä¹‰è¾“å‡º JSON æ ¼å¼")

    repl_svg.change(
        fn=show_repl_svg,
        inputs=repl_svg,
        outputs=new_svg
    )

    repl_img.change(
        fn=show_repl_img,
        inputs=repl_img,
        outputs=new_img
    )

    html_file.change(
        update_html_prev,
        inputs=html_file,
        outputs=html_preview
    )

    html_file.change(
        cal_token_count,
        inputs=[html_file, n_ctx_input],
        outputs=token_count
    )

    load_model_button.click(
        fn=lambda model_file, n_gpu_layers, n_ctx: load_model(
            os.path.join('models', model_file), n_gpu_layers, n_ctx
        ),
        inputs=[model_file_dropdown, n_gpu_layers_input, n_ctx_input],
        outputs=[model_load_info, model_type]
    )

    generate_button.click(
        fn=generate_response,
        inputs=[html_file, max_tokens_input, temperature_input, top_p_input, model_type, custom_instruction,
                json_schema, clean_html_cbox, repl_svg, repl_img, new_svg, new_img],
        outputs=output_text
    )

    render_button.click(
        fn=md_deliver,
        inputs=output_text,
        outputs=output_md
    )

    stop_button.click(
        fn=stop_generate,
        inputs=None,
        outputs=None
    )

    html_render_button.click(
        fn=html_deliver,
        inputs=html_preview,
        outputs=output_html
    )

    unload_model_button.click(
        fn=unload_model,
        inputs=None,
        outputs=model_load_info
    )

    copy_button.click(
        fn=copy,
        inputs=output_text,
        outputs=None
    )

    refresh_models_list_btn.click(
        fn=refresh_model_list,
        inputs=model_file_dropdown,
        outputs=model_file_dropdown
    )

demo.launch()
